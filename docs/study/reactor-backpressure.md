# 리액터 백프레셔(Backpressure) 심층 분석

## 0. 요약

- **백프레셔(Backpressure)** 는 _데이터 생산 속도_ 가 _소비 속도_ 를 초과할 때 시스템이 안정적으로 버틸 수 있게 해 주는 **흐름 제어 메커니즘**이다.
- 리액티브 스트림즈 명세는 `request(n)` 을 통해 **소비자가 처리 가능한 양만 요구**하도록 표준을 정의하고, Reactor는 이를 기반으로 `Mono`/`Flux` 에 백프레셔를 구현한다.
- 기본적인 백프레셔 구현은 `Subscriber` 또는 `BaseSubscriber` 에서 직접 `request(n)` 을 호출하는 방식이고, 고수준에서는 `buffer`, `take`, `limitRate`, `onBackpressureXXX` 등의 연산자를 통해 사용한다.
- 백프레셔는 다음 세 가지 관점에서 이해하면 쉽다.
  - **프로토콜 관점**: `Subscription.request(n)` 을 통한 수요(Demand) 기반 프로토콜
  - **전략 관점**: 버퍼링, 드롭(drop), 최신값 유지(latest), 에러(error) 등으로 과압을 처리하는 전략
  - **아키텍처 관점**: 마이크로서비스, 메시지 큐, DB 등 외부 시스템에 부담을 조절하는 도구
- 잘못된 백프레셔 설계는 메모리 폭증, GC 스톱더월, 타임아웃, 데이터 유실로 이어질 수 있으므로, **시스템 전체의 속도와 병목을 고려한 설계**가 필수다.

---

## 1. 백프레셔가 필요한 이유

### 1.1 생산자-소비자 속도 불균형

- 대부분의 시스템에서 데이터 **생산자(Publisher)** 와 **소비자(Subscriber)** 의 처리 속도는 다르다.
  - 예: 초당 수천 건의 이벤트를 생산하는 IoT 게이트웨이 vs 초당 수십 건만 처리 가능한 DB
  - 예: 대량 메시지를 발행하는 Kafka Topic vs 이를 읽어 처리하는 웹 애플리케이션
- 백프레셔가 없다면 발생할 수 있는 문제:
  - 처리되지 못한 데이터가 **메모리 버퍼에 계속 쌓임 → OOM**
  - 큐/버퍼가 가득 차면서 **지연(latency) 폭증**
  - 다운스트림 시스템(예: DB, 외부 API)에 **폭주 트래픽** 유입

### 1.2 기존 동기/블로킹 모델과 비교

- 전통적인 동기/블로킹 모델에서는 생산자가 느려지거나, 소비자가 느려지면 **자연스럽게 생산자 스레드가 블로킹**된다.
  - 예: JDBC 쿼리 결과를 한 건씩 읽으며 처리 → DB 응답 속도에 맞춰 처리
- 반면 리액티브 모델은 **비동기/논블로킹** 이므로, 생산자가 매우 빠르게 데이터를 발행해도 소비자 스레드가 즉시 막히지 않는다.
  - 따라서 **별도의 흐름 제어 메커니즘(백프레셔)** 가 없으면 생산자 속도가 방치된다.

---

## 2. 리액티브 스트림즈 명세에서의 백프레셔

### 2.1 핵심 인터페이스와 역할 복습

- `Publisher` : 데이터를 발행하는 쪽 (생산자)
- `Subscriber` : 데이터를 구독하고 처리하는 쪽 (소비자)
- `Subscription` : 두 컴포넌트 사이의 연결과 **수요(Demand) 관리**를 담당
- 핵심은 `Subscription.request(long n)` 이며, **`n` 개 만큼만 데이터가 전달될 것**임을 의미한다.

### 2.2 프로토콜 흐름

1. `Subscriber.subscribe(publisher)` 호출
2. `publisher` 가 `onSubscribe(subscription)` 호출로 `Subscription` 전달
3. `Subscriber` 가 `subscription.request(n)` 호출 → **수요(demand) 전달**
4. `Publisher` 는 최대 `n` 개까지 `onNext` 를 통해 데이터를 보내고, 더 보내고 싶으면 다시 `request` 를 기다려야 한다.
5. 더 이상 필요 없으면 `subscription.cancel()` 로 종료

→ 요약하면, **“Publisher는 마음대로 푸시하지 말고, Subscriber가 요청한 만큼만 보내라”** 가 백프레셔의 룰이다.

---

## 3. Reactor에서의 백프레셔 기본 동작

### 3.1 기본 구현: 요청 기반(push-pull 하이브리드)

- Reactor의 `Flux`/`Mono` 는 리액티브 스트림즈 명세를 준수하므로, 내부적으로 항상 **수요 기반(demand-driven)** 으로 동작한다.
- 하지만 대부분의 고수준 API에서는 `request(n)` 을 직접 호출하지 않고 **기본 값**에 의존한다.
  - 예: 단순 `subscribe()` 시 Reactor는 적절한 버퍼 크기와 요청 전략을 내부적으로 결정한다.

### 3.2 냉/열(Cold/Hot) 퍼블리셔와 백프레셔

- **콜드(Cold) 퍼블리셔**
  - 구독 시점에 **초기 상태에서부터** 데이터를 다시 만들어 내는 스트림.
  - 예: `Flux.range`, `Flux.fromIterable`, `Mono.just` 등.
  - 백프레셔 관점에서 **구독자별로 독립적인 흐름**을 가지므로, 각 구독자가 요청한 만큼만 데이터를 생성하면 된다.

- **핫(Hot) 퍼블리셔**
  - 구독자 유무와 상관 없이 **독립적으로 데이터 생산이 계속되는 스트림**.
  - 예: `Flux.interval`, 외부 이벤트 브로커, UI 이벤트 스트림 등.
  - 백프레셔가 어렵거나 부분적으로만 가능하다.
    - 생산자 쪽을 늦출 수 없으면, 중간에서 **버퍼링, 드롭, 최신값 유지** 같은 전략으로 과압을 다룬다.

---

## 4. BaseSubscriber를 이용한 수요 직접 제어

### 4.1 `BaseSubscriber` 소개

- `reactor.core.publisher.BaseSubscriber<T>` 는 `Subscriber<T>` 의 추상 구현체로, 몇 가지 훅 메서드를 제공한다.
- 백프레셔 제어에 중요한 메서드:
  - `hookOnSubscribe(Subscription subscription)` : 구독 시작 시점 처리
  - `hookOnNext(T value)` : 데이터 수신 시점 처리
  - (필요 시) `hookOnComplete`, `hookOnError`, `hookOnCancel` 등

### 4.2 단계적 요청 예시 시나리오

- 예시 상황
  - 생산자: `Flux.range(1, 1000)` → 매우 빠르게 1000개의 숫자를 생산할 수 있음
  - 소비자: 숫자 하나를 처리하는 데 200ms 걸리는 느린 작업

- 단계적 요청 전략
  1. `hookOnSubscribe` 에서 `request(1)` 호출 → “우선 1개만 줘”
  2. `hookOnNext` 에서 받은 데이터를 처리 (200ms 소요)
  3. 처리 완료 후 다시 `request(1)` 호출 → “다음 1개 줘”

- 이 패턴의 효과
  - 생산자는 잠재적으로 매우 빠르지만, 실제로는 **소비자가 요청하는 속도에 맞춰** 데이터를 내보낸다.
  - 즉, 소비자가 시스템의 **속도 조절 밸브** 역할을 한다.

### 4.3 동적 요청량 조절

- 더 나아가, `hookOnNext` 내부에서
  - 현재 큐 길이, CPU 사용률, 응답 시간 등을 참고해
  - 다음에 요청할 개수 `n` 을 동적으로 조절할 수 있다.
- 예:
  - CPU 여유가 있으면 `request(10)` 으로 벌크 처리
  - 부하가 크면 `request(1)` 으로 줄여 “되도록 천천히” 처리

---

## 5. onBackpressure 연산자: 과압에 대한 전략 선택

Reactor는 **생산 속도를 올릴 수밖에 없는 소스** 앞에 `onBackpressureXXX` 연산자를 둠으로써, 과압 상황에서의 정책을 선택하게 한다.

### 5.1 공통 전제

- 주로 **핫 소스** 나 `Flux.generate`, `Flux.create` 같은 하위 수준 API에 붙여 사용한다.
- 다운스트림에서 요청한 개수보다 더 많은 데이터가 빠르게 들어오는 경우에 동작한다.

### 5.2 `onBackpressureBuffer` – 버퍼에 쌓기

- 역할
  - 요청량을 초과해 들어온 데이터를 **메모리 버퍼에 임시 저장**한다.
- 특징
  - 소비자가 느려도 데이터를 최대한 놓치지 않고 보존한다.
  - 버퍼 크기를 제한하지 않으면 **메모리 폭증 위험**이 있다.
- 주요 옵션 (오버로드)
  - `onBackpressureBuffer(int capacity)` : 버퍼 최대 개수 지정
  - `onBackpressureBuffer(int capacity, BufferOverflowStrategy strategy)` : 넘칠 때 전략 지정
  - `onBackpressureBuffer(int capacity, Consumer<? super T> onOverflow, BufferOverflowStrategy strategy)` : 넘칠 때 콜백 + 전략
- Overflow 전략 예
  - `ERROR` : 넘치면 예외 발생
  - `DROP_LATEST` : 새로 들어온 데이터 버림
  - `DROP_OLDEST` : 가장 오래된 데이터 제거 후 새 데이터 삽입

### 5.3 `onBackpressureDrop` – 초과 데이터 즉시 버리기

- 역할
  - 다운스트림이 처리할 준비가 안된 상태에서 들어오는 데이터는 **즉시 폐기(drop)** 한다.
- 특징
  - 메모리 사용량은 안정적으로 유지할 수 있지만, **데이터 유실을 감수**해야 한다.
  - 실시간 모니터링 / 메트릭 등 “대략적인 추세만 보면 되는” 경우에 적합.
- 콜백
  - `onBackpressureDrop(Consumer<? super T> onDrop)` 을 사용해 버려진 데이터를 로깅하거나 별도 처리 가능.

### 5.4 `onBackpressureLatest` – 최신 데이터만 유지

- 역할
  - 과압이 걸릴 경우, 버퍼에 **맨 마지막 데이터만 유지**하고 나머지는 버린다.
- 특징
  - 소비자는 항상 **가장 최신 상태**를 받게 되며, 중간 상태는 버려진다.
  - UI 업데이트, 실시간 대시보드 등 “최신값만 중요”한 시나리오에 유용.

---

## 6. 고수준 연산자와 백프레셔의 관계

### 6.1 `buffer`와 백프레셔

- `buffer` 는 본질적으로 **수집 연산자**이지만, 백프레셔 측면에서도 의미가 있다.
  - 단건 처리 대신 **배치 단위**로 처리하게 만들어 다운스트림 호출 수를 줄인다.
  - 예: DB 벌크 인서트, 외부 API 배치 호출 등
- 주의점
  - 버퍼가 너무 크거나, 플러시 조건이 너무 느슨하면 **메모리 사용량 증가** 및 **지연 시간 증가**를 초래할 수 있다.
  - 특히 핫 퍼블리셔와 결합 시, 마지막 버퍼가 조건 불충족으로 방출되지 않아 데이터가 "숨는" 경우를 주의해야 한다.

### 6.2 `take`와 백프레셔

- `take` 는 **흐름 차단 연산자**로, 일정 조건 이후에는 스트림을 종료한다.
  - 필요 이상으로 들어오는 데이터에 대해 **논리적 상한선**을 설정하는 효과가 있다.
  - 예: 최대 100건까지만 처리, 10초까지만 수집 등
- 단, `take` 는 **근본적인 백프레셔 구현**이라기보다는, 상위 레벨에서 “더 이상 받지 않겠다”는 한계를 정의하는 용도에 가깝다.

### 6.3 `limitRate` – 요청 단위를 조절하는 연산자

- `limitRate(int prefetch)`
  - 다운스트림에서 소스를 향해 한 번에 요청할 개수(prefetch)를 제한한다.
  - Reactor 기본 prefetch 값은 보통 256 등으로 설정되어 있으며, 이를 조절해 **Chunk 크기**를 변경할 수 있다.
- 활용 예
  - DB나 외부 API 호출이 비싼 경우, 너무 많은 데이터를 한 번에 끌어오지 않도록 rate를 조절.

---

## 7. 스레드/스케줄러와 백프레셔

### 7.1 `publishOn` / `subscribeOn` 과의 상호작용

- `publishOn(scheduler)`
  - 이후 연산 단계의 실행 스레드를 변경한다.
  - 내부적으로는 큐를 사용해 데이터/신호를 전달하며, 이 과정에서 **큐 크기와 요청 전략**이 백프레셔에 영향을 준다.
- `subscribeOn(scheduler)`
  - 소스 Publisher의 구독 및 데이터 생성이 어떤 스레드에서 일어날지 결정한다.
- 과도한 `publishOn` 사용은
  - 스레드 간 큐 이동이 많아져 **메모리/컨텍스트 스위칭 비용 + 지연 시간**을 늘릴 수 있다.

### 7.2 Bounded Elastic 스케줄러

- `Schedulers.boundedElastic()` 은 IO 작업을 위해 **최대 스레드 수가 제한된 스레드 풀**을 제공한다.
- 스레드 수가 한계에 도달하면, 새로운 작업은 큐에 대기한다.
- 이는 스레드라는 리소스에 대한 일종의 **백프레셔**로 볼 수 있다.

---

## 8. 시스템 아키텍처 관점의 백프레셔 패턴

### 8.1 메시지 큐와 토픽

- Kafka, RabbitMQ, SQS 같은 메시지 브로커는 자연스럽게 **백프레셔 지점** 역할을 한다.
  - 생산자는 토픽/큐에 메시지를 쌓고, 소비자는 자신의 속도에 맞춰 읽어 간다.
  - 큐의 깊이(depth)를 모니터링해 시스템 부하를 간접적으로 파악할 수 있다.
- Reactor 기반 애플리케이션에서
  - 메시지 리스너를 `Flux`/`Mono` 로 감싸고, 소비자 측에서 `request` 전략과 `onBackpressureXXX` 를 조합하면
  - 브로커와 애플리케이션 사이에 이중의 보호막을 세울 수 있다.

### 8.2 외부 시스템 보호

- DB, 외부 REST API, 서드파티 서비스는 종종 **전체 시스템의 병목 지점**이 된다.
- Reactor를 사용하면 다음과 같은 도구를 조합해 외부 시스템을 보호할 수 있다.
  - `limitRate` / `take`: 전체 호출량 상한 설정
  - `buffer` + 시간 기반 플러시: 호출을 묶어서 보내 부하를 완화
  - `retryBackoff`: 실패 시 점진적 재시도(backoff)를 통해 재압박 방지
  - 서킷 브레이커(Resilience4j 등)와 결합: 일정 수준 이상 실패 시 자동 차단

---

## 9. 백프레셔 설계 시 자주 하는 실수

1. **버퍼만 키우는 접근**
   - 당장은 문제를 덮어버리지만, 결국 **폭발 지점을 뒤로 미루는 것일 뿐**이다.
   - 해결책: 데이터 생산량을 조절하거나, 다운스트림 처리 속도를 높이는 근본적인 접근 필요.

2. **핫 퍼블리셔를 콜드처럼 가정**
   - 실제로는 계속 데이터가 들어오는데, 테스트에서는 작은 데이터셋으로만 검증해 문제를 놓치기 쉽다.
   - 해결책: 장시간 테스트, 부하 테스트를 통해 실제 운영 수준의 데이터량으로 검증.

3. **데이터 유실 허용 여부를 명확히 정의하지 않음**
   - `onBackpressureDrop`/`Latest` 사용 시, 무엇을 잃어도 괜찮고 무엇은 절대 잃으면 안 되는지 구분해야 한다.

4. **백프레셔를 애플리케이션 레벨에만 두고 인프라 레벨을 무시**
   - 메시지 브로커, DB, API Gateway, 스레드 풀 등 인프라 레벨의 보호장치를 함께 고려해야 한다.

---

## 10. 정리

- 백프레셔는 리액티브 프로그래밍에서 **가장 중요한 개념 중 하나**로, 시스템이 안정적으로 고부하를 견디는지 여부를 결정한다.
- 리액티브 스트림즈 명세는 `Subscription.request(n)` 을 통해 **소비자 주도(Consumer-driven)** 의 수요 제어 모델을 정의하고, Reactor는 이를 따르는 다양한 API와 연산자를 제공한다.
- 실무에서는 다음 세 가지 축을 항상 함께 생각해야 한다.
  1. **프로토콜**: `request`/`cancel` 을 어떻게 설계할 것인가?
  2. **전략**: 버퍼, 드롭, 최신값, 에러 중 어떤 전략을 선택할 것인가?
  3. **아키텍처**: 메시지 큐, DB, 외부 API, 스레드 풀 등 주변 시스템과의 관계에서 어디에 병목이 있는가?
- 단순히 “에러가 안 나면 된다” 수준을 넘어서, **부하가 급증해도 예측 가능한 방식으로 동작하는 시스템**을 설계하기 위해서는 백프레셔에 대한 깊은 이해와 주기적인 부하 테스트가 필수다.
